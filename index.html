<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SpaceMARL- Multi-Agent Reinforcement Learning Framework for Satellite Proximity Operations ">
  <meta name="keywords" content="SpaceMARL">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SpaceMARL- Multi-Agent Reinforcement Learning Framework for Satellite Proximity Operations</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://sydneyidolan.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SpaceMARL- Multi-Agent Reinforcement Learning Framework for Satellite Proximity Operations</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="sydneyidolan.com">Sydney Dolan</a>,</span>
            <span class="author-block">
              <a href="https://nsidn98.github.io">Siddharth Nayak</a>,</span>
            <span class="author-block">
              <a href="https://web.mit.edu/hamsa/www/">Hamsa Balakrishnan</a></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Massachusetts Institute of Technology</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2211.03658"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/sydneyid/satellite-cooperative-nav"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Environment Code</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/sydneyid/satellite-min-info/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Poster. -->
              <span class="link-block">
                <a href="./static/images/Portrait_Mode_L4DC_Poster.pdf"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Poster</span>
                  </a>
              </span>


            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We explore space traffic management as an application of collision-free navigation in multi-agent systems where vehicles have limited observation and communication ranges. We investigate the effectiveness of transferring a collision avoidance multi-agent reinforcement (MARL) model trained on a ground environment to a space one. We demonstrate that the transfer learning model outperforms a model that is trained directly on the space environment. Furthermore, we find that our approach works well even when we consider the perturbations to satellite dynamics caused by the Earth's oblateness. Finally, we show how our methods can be used to evaluate the benefits of information-sharing between satellite operators in order to improve coordination.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<!--/ Motivation. -->
<section class="section" id="Motivation">
  <div class="container is-max-desktop content">
    <h2 class="title">Motivation</h2>
  <p>The burdening of manual collision avoidance services motivates the development of autonomous decentralized space traffic management. In contrast to traditional centralized conjunction analysis, decentralized traffic management refers to a system where the management and coordination of satellite movements are distributed across multiple independent nodes and entities. In such a system, satellites and satellite operators communicate and collaborate directly with one another to ensure safe navigation and avoid conflicts. Decentralized space traffic management services could enhance the resilience and responsiveness of space operations, enabling faster decision-making, reducing single points of failure, and fostering greater collaboration among international stakeholders in a congested space environment.</p>
  <p>This work explores the use of multi-agent reinforcement learning (MARL) techniques to facilitate decentralized space traffic management. We examine the effectiveness of decentralized MARL methodologies in this domain, and introduce our technique, SpaceMARL, a decentralized MARL method that uses graph transformers to augment communication between agents. Through experiments, we demonstrate the strong performance of our method, and its ability to model the value of different pieces of information through its graph formulation.</p>
  </div>
</section>


<!--/ Methods. -->
<section class="section" id="Methods">
  <div class="container is-max-desktop content">
    <h2 class="title">Methods</h2>
    <embed src="./static/images/GNN_JGCD.pdf" type="application/pdf" width="100%" height="600px" />
      <p><b>Figure 1.</b>Graph Neural Network Architecture. Each satellite within the environment is represented as a node, and communications between satellites are represented as edges. Each node represents a particular spacecraft, which means that that specific node can encode specific qualities including size of the spacecraft, its capabilities, and its precise location. Each edge represents communication and sensing abilities, so they can encode qualities related to the relative information between two satellites including their relative distances, the areas they have both surveyed or other characteristics associated with path planning. Our graph formulation is dynamic, meaning that the over the course of the simulation, the satellites can adaptively connect and disconnect with one another depending on the satellites ability to sense those in their proximity. We rely on a unified message passing model (UniMP), a variant of a graph transformer, to allow the agents to selectively prioritize messages coming from their neighbors according to their importance. We use multiple layers of this message-passing so that information can be propagated between agents that are higher-order neighbors with each other.  </p>
  </div>
</section>

<section class="section" id="Comparisons Against Other Methods">
  <div class="container is-max-desktop content">
    <h2 class="title">Comparisons Againsts Other Methods</h2>
    <p>We compare our method with a few different MARL baselines in the rendezvous environment. The following metrics are compared</p>
     <ul>
      <li>Total reward obtained in an episode by all the agents (higher is better)</li>
      <li>Fraction of episode taken by the agents to reach the goal, T (lower is better)</li>
      <li>The total number of collisions the agents had in an episode, # col (lower is better)</li>
      <li>Percent of episodes in which all agents get to their goals, S% (higher is better) </li>
    </ul>
    
    <iframe src="./static/images/ThreeTaskDescriptions.pdf"
        class="center-image"
        width="100%"
        height="600px">
      </iframe>
        <p><b>Figure 2.</b> Three Control Tasks test in our algorithm</p>
        We use the following control tasks:
    <ul>
      <li><i>Rendezvous</i> - Each agent tries to reach its preassigned goal  while avoiding collisions with other entities in the environment.</li>
      <li><i>Cluster Formation</i> - There is a single landmark, and the agents try to position themselves in an N-sided regular polygon with the landmark at its center.</li>
      <li><i>Trailing Formation</i> - There are two landmarks, and the agents try to position themselves equally spread out in a line between the two</li>
 </ul>
<p>We compare our method against several other MARL baselines in the <i>Rendezvous</i> environment during training. </p>
<iframe src="./static/images/SpaceMARL.pdf"
        width="450"
        height="600"
        class="center-image"
        style="border: none;">
</iframe>
<p><b>Figure 3.</b>Comparison of the training performance of SpaceMARL with the best-performing baselines using global and local information. SpaceMARL significantly outperforms most baseline algorithms. Through the use of transfer learning, where the system is initially trained on a ground environment, and then the weights from that environment are applied to the space environment, we can further stabilize training and performance. While RMAPPO has a similar performance, it requires global information. Refer to the paper for a more extended discussion.</p>

<p>Then, in execution, we compare SpaceMARL against the best performing baseline, RMAPPO in each of the three control tasks. </p>
<img src="./static/images/Tasks_execution.png" width="700"
        class="center-image"
        alt="TODO: alt text"/>
<p><b>Figure 4.</b> Performance of Global RMAPPO, Local RMAPPO and SpaceMARL on the <i>rendezvous, cluster formation</i>, and <i>trailing formation</i> tasks.</p>

</section>

<section class="section" id="Impact of Sharing Goal Information">
  <div class="container is-max-desktop content">
    <h2 class="title">Impact of Sharing Goal-Information</h2>
    <p> We use our model to evaluate the value of satellites sharing goal information (i.e., sharing their orbits, and any associated changes) with each other. To do this, we consider the SpaceMARL model that was trained from scratch in the space environment. We alter the previous experimental set-up to focus on $N=2$ satellites. We initialize the satellites such that they both have the same distance to travel to their respective goals. Furthermore, their respective initial positions and goals are set so that their most direct path from the start to the goal intersects with the other satellites midway through their path.</p> 
    <p>To focus on the information learned directly from sharing, we compare two cases: the first in which the satellites are sharing their goal information with each other (the \emph{sharing} case), and the second in which they are not (the \emph{hidden} case). Goal-sharing can be thought of as a proxy for the future movements of the satellite, as it will seek to move towards the goal over the course of an episode. 
      <img src="./static/images/Value_sharing.png"    class="center-image"
      alt="TODO: alt text"/>
      <p><b>Figure 5.</b>Percentage improvements through goal information-sharing, results are averaged over 100 evaluation episodes.</p>


  </div>
</section>



<section class="section" id="Conclusions">
  <div class="container is-max-desktop content">
    <h2 class="title">Conclusions</h2>
    We propose SpaceMARL: a multi-agent reinforcement learning method for multi-satellite coordination. We demonstrated
     <ul>
      <li>The effectiveness of graph transformers to aid in decentralized proximity operations coordination for satellites.</li>
      <li>Transfer learning from ground-based to space-based environments improves performance in training.</li>
      <li>Goal-sharing among satellites improved safety and path-planning efficiency, reducing traveled distance by 80% and getting closer to goals by 27%.</li>
    </ul>
    Future work includes developing more realistic simulations, accounting for communication delays, adding safety guarantees, and designing incentives for information-sharing.
  </div>
</section>


<section class="section" id="Citation">
  <div class="container is-max-desktop content">
    <h2 class="title">Citation</h2>
    <p> If you find our work or code useful in your research, please consider citing the following: </p>
    <pre><code>@article{spacemarl,
author={{Dolan, Sydney and Nayak, Siddharth and Balakrishnan, Hamsa},
journal={Learning for Dynamics and Control Conference},
title={Satellite Navigation and Coordination with Limited Information Sharing},
publisher ={Proceedings of Machine Learning Research},
year={2023},
pages={1058–1071}
}</code></pre>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            This work is part of a broader research thread around multi-agent coordination with limited information sharing. Other work from the Dynamics INfrastructrue and Mobility Lab (DINaMo) includes
            <ul>
              <li><a href="https://nsidn98.github.io/InforMARL/">InforMARL</a> - a generalized multi-agent reinforcement learning approach for ground-based settings .</li>
              <li><a href="https://dl.acm.org/doi/pdf/10.1145/3702012">FairMARL</a> - a multi-agent reinforcement learning approach to balance fairness in resource-constrainted, limited information systems.</li>
              <li><a href="https://arxiv.org/pdf/2502.00558">asynCoMARL</a> - a multi-agent reinforcement learning approach that focuses on the problem of coordinating agetns that are working with asynchronous action and communication taking.</li>
            </ul>
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->
  </div>
</section>




<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    <p> The authors would like to thank the MIT SuperCloud and the Lincoln Laboratory Supercomputing Center for providing high performance computing resources that have contributed to the research results reported within this paper. The NASA University Leadership initiative (grant #80NSSC20M0163) provided funds to assist the authors with their research, but this article solely reflects the opinions and conclusions of its authors and not any NASA entity. This research was sponsored in part by the United States AFRL and the United States Air Force Artificial Intelligence Accelerator and was accomplished under Cooperative Agreement Number FA8750-19-2-1000. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the United States Air Force or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notion herein. Sydney Dolan was supported by the National Science Foundation Graduate Research Fellowship under Grant No. 1650114. </p>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is based that used by <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template.
          </p>
        </div>
      </div>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


</body>
</html>
